{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnielG\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pywrap_tensorflow_internal\n",
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#scikit learn  library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "#Use LogisticRegression for classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"inputs\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('inputs/train.csv')\n",
    "test = pd.read_csv('inputs/test.csv')\n",
    "sample_sub  = pd.read_csv('inputs/sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product(str):\n",
    "    if \";\"  in str:\n",
    "        prd_lst = str.split(\";\")\n",
    "        count_item = len(prd_lst)\n",
    "        first_lv1 = prd_lst[0].split(\"/\")[0]\n",
    "        first_lv2 = prd_lst[0].split(\"/\")[1]\n",
    "        first_lv3 = prd_lst[0].split(\"/\")[2]\n",
    "        first_lv4 = prd_lst[0].split(\"/\")[3]\n",
    "        \n",
    "        lv1_lst =[]\n",
    "        lv2_lst =[]\n",
    "        lv3_lst =[]\n",
    "        lv4_lst =[]\n",
    "        for item in prd_lst:\n",
    "            lv1_lst.append(item.split(\"/\")[0])\n",
    "            lv2_lst.append(item.split(\"/\")[1])\n",
    "            lv3_lst.append(item.split(\"/\")[2])\n",
    "            lv4_lst.append(item.split(\"/\")[3])\n",
    "            \n",
    "        unique_lv1 = len(set(lv1_lst))\n",
    "        unique_lv2 = len(set(lv2_lst))\n",
    "        unique_lv3 = len(set(lv2_lst))\n",
    "        unique_lv4 = len(set(lv2_lst))\n",
    "        most_freq_lv1 =  max(lv1_lst, key=Counter(lv1_lst).get)        \n",
    "    else:\n",
    "        lv_lst = str.split(\"/\")\n",
    "        first_lv1 = lv_lst[0]\n",
    "        first_lv2 = lv_lst[1]\n",
    "        first_lv3 = lv_lst[2]\n",
    "        first_lv4 = lv_lst[3]\n",
    "        \n",
    "        count_item = 1\n",
    "        unique_lv1 = 1\n",
    "        unique_lv2 = 1\n",
    "        unique_lv3 = 1\n",
    "        unique_lv4 = 1\n",
    "        \n",
    "        most_freq_lv1 = first_lv1\n",
    "    return (count_item,first_lv1,first_lv2,first_lv3,first_lv4,unique_lv1,unique_lv2,unique_lv3,unique_lv4,most_freq_lv1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullproductlist = pd.concat([train['ProductList'], test['ProductList']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullproductlist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_col_lst = fullproductlist.apply(lambda x: extract_product(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction :\n",
    "new_col = ('NumProduct','FirstA','FirstB','FirstC','FirstD','UniqueA','UniqueB','UniqueC','UniqueD','MostA')      \n",
    "#new_col_lst = fullproductlist.apply(lambda x: extract_product(x))    \n",
    "\n",
    "new_col_lst = train['ProductList'].apply(lambda x: extract_product(x))    \n",
    "new_col_df = pd.DataFrame(new_col_lst.tolist(),columns =new_col)\n",
    "train = pd.concat([train, new_col_df], axis=1)\n",
    "\n",
    "new_col_lst = None\n",
    "new_col_df = None\n",
    "\n",
    "new_col_lst = test['ProductList'].apply(lambda x: extract_product(x))    \n",
    "new_col_df = pd.DataFrame(new_col_lst.tolist(),columns =new_col)\n",
    "test = pd.concat([test, new_col_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10500, 15), (4500, 14))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(train.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time feature extraction\n",
    "train['startTime'] = pd.to_datetime(train['startTime'])\n",
    "train['endTime'] = pd.to_datetime(train['endTime'])\n",
    "train['duration'] = train['endTime'] - train['startTime']\n",
    "train['duration'] = train['duration'].astype('timedelta64[m]')\n",
    "train['weekday'] = train['startTime'].dt.dayofweek\n",
    "train['hour_24h'] = train['startTime'].dt.hour\n",
    "\n",
    "#Date Features\n",
    "train['day'] = train['startTime'].dt.day\n",
    "train['weekend'] = (train['startTime'].dt.weekday >=5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['startTime'] = pd.to_datetime(test['startTime'])\n",
    "test['endTime'] = pd.to_datetime(test['endTime'])\n",
    "test['duration'] = test['endTime'] - test['startTime']\n",
    "test['duration'] = test['duration'].astype('timedelta64[m]')\n",
    "test['weekday'] = test['startTime'].dt.dayofweek\n",
    "test['hour_24h'] = test['startTime'].dt.hour\n",
    "\n",
    "#Date Features\n",
    "test['day'] = test['startTime'].dt.day\n",
    "test['weekend'] = (test['startTime'].dt.weekday >=5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['session_id', 'startTime', 'endTime', 'ProductList']\n",
    "#train = train.drop(drop_lst,axis =1 )\n",
    "#test = test.drop(drop_lst,axis =1 )\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gender'] = train['gender'].map({'female':1,'male':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2599e1d9668>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_srs = train.gender.value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_lst = ['session_id', 'startTime', 'endTime', 'ProductList']\n",
    "# X_train = train.drop(drop_lst,axis =1 )\n",
    "# Y_train = train['gender']\n",
    "# X_train = X_train.drop('gender',axis = 1)\n",
    "    \n",
    "# X_test =  test.drop(drop_lst,axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regularized Expanding mean scheme\n",
    "for features in ['FirstA','FirstB','FirstC', 'FirstD', 'MostA']:\n",
    "    cumsum = train.groupby(features)['gender'].cumsum() - train['gender']\n",
    "    cumcnt = train.groupby(features).cumcount()\n",
    "    train[features + 'meantarget'] = cumsum/cumcnt\n",
    "    test[features + 'meantarget'] = cumsum/cumcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['session_id', 'startTime', 'endTime', 'ProductList']\n",
    "data = pd.concat([train, test])\n",
    "data = data.drop(drop_lst,axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 21)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'startTime', 'endTime', 'ProductList', 'gender',\n",
       "       'NumProduct', 'FirstA', 'FirstB', 'FirstC', 'FirstD', 'UniqueA',\n",
       "       'UniqueB', 'UniqueC', 'UniqueD', 'MostA', 'duration', 'weekday',\n",
       "       'hour_24h', 'day', 'weekend', 'FirstAmeantarget', 'FirstBmeantarget',\n",
       "       'FirstCmeantarget', 'FirstDmeantarget', 'MostAmeantarget'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4495    0\n",
       "4496    0\n",
       "4497    1\n",
       "4498    0\n",
       "4499    0\n",
       "Name: weekend, Length: 15000, dtype: int32"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['day', 'weekend','FirstAmeantarget', 'FirstBmeantarget','FirstCmeantarget', 'FirstDmeantarget', 'MostAmeantarget']\n",
    "\n",
    "X_train = data.loc[data.gender.isnull() == False].drop(drop_lst,axis =1 )\n",
    "Y_train = train['gender']\n",
    "X_train = X_train.drop('gender',axis = 1)\n",
    "\n",
    "X_test =  data.loc[data.gender.isnull()] .drop(drop_lst,axis =1 )\n",
    "X_test = X_test.drop('gender',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data.loc[data.gender.isnull() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding for categories features\n",
    "#X_train = pd.get_dummies(X_train)\n",
    "#X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(train.isnull().any())\n",
    "#train.head()\n",
    "#list(train.isnull().any())\n",
    "\n",
    "X_train= X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7140, 11548)\n",
      "(1785, 11548)\n"
     ]
    }
   ],
   "source": [
    "val_size = 0.25\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=val_size)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(class_weight = {1:.1, 0:.35})\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalute based on validation set\n",
      "f1 :  0.9280055115397865\n",
      "accuracy score 0.8829131652661064\n",
      "recall score micro:  0.8829131652661064\n",
      "recall score macro:  0.7767943297412365\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalute based on validation set\")\n",
    "\n",
    "print(\"f1 : \" + \" %s\" % f1_score(Y_val, clf.predict(X_val)))\n",
    "\n",
    "print(\"accuracy score\" + \" %s\" % accuracy_score(Y_val, clf.predict(X_val)))\n",
    "print(\"recall score micro: \" + \" %s\" % recall_score(Y_val, clf.predict(X_val), average='micro'))\n",
    "print(\"recall score macro: \" + \" %s\" % recall_score(Y_val, clf.predict(X_val), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 11548), (7140, 11548))"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "predresults = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=predresults, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_11th_April_1.2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 2), (4500, 1))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub.shape,results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['day', 'weekend','FirstAmeantarget', 'FirstBmeantarget','FirstCmeantarget', 'FirstDmeantarget', 'MostAmeantarget']\n",
    "\n",
    "X_train = data.loc[data.gender.isnull() == False].drop(drop_lst,axis =1 )\n",
    "Y_train = train['gender']\n",
    "X_train = X_train.drop('gender',axis = 1)\n",
    "\n",
    "X_test =  data.loc[data.gender.isnull()] .drop(drop_lst,axis =1 )\n",
    "X_test = X_test.drop('gender',axis = 1)\n",
    "X_train= X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8623809523809524\n",
      "\n",
      "2 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.86\n",
      "\n",
      "3 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8633333333333333\n",
      "\n",
      "4 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8809523809523809\n",
      "\n",
      "5 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8595238095238096\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \n",
    "\n",
    "for train_index,test_index in kf.split(X_train,Y_train):     \n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))   \n",
    "\n",
    "    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]     \n",
    "    ytr,yvl = Y_train[train_index],Y_train[test_index]         \n",
    "\n",
    "    model = LogisticRegression(random_state=1)     \n",
    "    model.fit(xtr, ytr)     \n",
    "    pred_test = model.predict(xvl)     \n",
    "    score = accuracy_score(yvl,pred_test)     \n",
    "    print('accuracy_score',score)     \n",
    "    i+=1 \n",
    "\n",
    "pred_test = model.predict(X_test) \n",
    "pred=model.predict_proba(xvl)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_11th_April_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8726666666666667\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "num_leafs = [1, 5, 10]\n",
    "depths = [3, 5, 10] #np.arange(1, 20)\n",
    "min_split = [3, 5, 10] #np.arange(1, 10)\n",
    "\n",
    "param_grid = [{'max_depth':depths,\n",
    "              'min_samples_leaf':num_leafs,\n",
    "              'min_samples_split':min_split}]\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1)   \n",
    "\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "gs = gs.fit(X_train, Y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8642857142857143\n",
      "\n",
      "2 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8661904761904762\n",
      "\n",
      "3 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8685714285714285\n",
      "\n",
      "4 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8833333333333333\n",
      "\n",
      "5 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \n",
    "\n",
    "\n",
    "for train_index,test_index in kf.split(X_train,Y_train):     \n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))   \n",
    "\n",
    "    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]     \n",
    "    ytr,yvl = Y_train[train_index],Y_train[test_index]        \n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=1,max_depth =  5,min_samples_leaf=10, min_samples_split=3)     \n",
    "    model.fit(xtr, ytr)     \n",
    "    pred_test = model.predict(xvl)     \n",
    "    score = accuracy_score(yvl,pred_test)     \n",
    "    print('accuracy_score',score)     \n",
    "    i+=1 \n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_11th_April_DT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8609523809523809\n",
      "\n",
      "2 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8652380952380953\n",
      "\n",
      "3 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8642857142857143\n",
      "\n",
      "4 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8795238095238095\n",
      "\n",
      "5 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8652380952380953\n"
     ]
    }
   ],
   "source": [
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \n",
    "for train_index,test_index in kf.split(X_train,Y_train):     \n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))   \n",
    "\n",
    "    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]     \n",
    "    ytr,yvl = Y_train[train_index],Y_train[test_index]        \n",
    "    \n",
    "    model = RandomForestClassifier(random_state=1, max_depth=15, n_estimators=500,class_weight = {1:.1, 0:.35})\n",
    "    #,\n",
    "    model.fit(xtr, ytr)     \n",
    "    pred_test = model.predict(xvl)     \n",
    "    score = accuracy_score(yvl,pred_test)     \n",
    "    print('accuracy_score',score)     \n",
    "    i+=1 \n",
    "\n",
    "pred_test = model.predict(X_test) \n",
    "#pred2=model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_11th_April_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBalancedSampleWeights(y_train, largest_class_weight_coef):\n",
    "    classes = np.unique(y_train, axis = 0)\n",
    "    classes.sort()\n",
    "    class_samples = np.bincount(y_train)\n",
    "    total_samples = class_samples.sum()\n",
    "    n_classes = len(class_samples)\n",
    "    weights = total_samples / (n_classes * class_samples * 1.0)\n",
    "    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n",
    "    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * largest_class_weight_coef\n",
    "    sample_weights = [class_weight_dict[y] for y in y_train]\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_class_weight_coef = max(train['gender'].value_counts().values)/Y_train.shape[0]\n",
    "\n",
    "#pass y_train as numpy array\n",
    "weight = CreateBalancedSampleWeights(Y_train, largest_class_weight_coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8192\n",
       "0    2308\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2308"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.28173828125"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'scale_pos_weight'] = sum_wneg/sum_wpos\n",
    "train['gender'].value_counts()\n",
    "train['gender'].value_counts()[0]\n",
    "train['gender'].value_counts()[1]\n",
    "scale_pos_weight = train['gender'].value_counts()[0]/ train['gender'].value_counts()[1]\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1,\n",
       "              weights=[0.5, 2.2746967071057194, 0.5, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 2.2746967071057194, 2.2746967071057194, 0.5,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5, 0.5, 0.5,\n",
       "                       0.5, 0.5, 2.2746967071057194, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5,\n",
       "                       2.2746967071057194, ...])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8642857142857143\n",
      "\n",
      "2 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1,\n",
       "              weights=[0.5, 2.2746967071057194, 0.5, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 2.2746967071057194, 2.2746967071057194, 0.5,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5, 0.5, 0.5,\n",
       "                       0.5, 0.5, 2.2746967071057194, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5,\n",
       "                       2.2746967071057194, ...])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8709523809523809\n",
      "\n",
      "3 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1,\n",
       "              weights=[0.5, 2.2746967071057194, 0.5, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 2.2746967071057194, 2.2746967071057194, 0.5,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5, 0.5, 0.5,\n",
       "                       0.5, 0.5, 2.2746967071057194, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5,\n",
       "                       2.2746967071057194, ...])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8704761904761905\n",
      "\n",
      "4 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1,\n",
       "              weights=[0.5, 2.2746967071057194, 0.5, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 2.2746967071057194, 2.2746967071057194, 0.5,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5, 0.5, 0.5,\n",
       "                       0.5, 0.5, 2.2746967071057194, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5,\n",
       "                       2.2746967071057194, ...])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8838095238095238\n",
      "\n",
      "5 of kfold 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1,\n",
       "              weights=[0.5, 2.2746967071057194, 0.5, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 2.2746967071057194, 2.2746967071057194, 0.5,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5, 0.5, 0.5,\n",
       "                       0.5, 0.5, 2.2746967071057194, 0.5, 2.2746967071057194,\n",
       "                       0.5, 0.5, 0.5, 2.2746967071057194, 0.5, 0.5,\n",
       "                       2.2746967071057194, ...])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8695238095238095\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \n",
    "for train_index,test_index in kf.split(X_train,Y_train):     \n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))   \n",
    "\n",
    "    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]     \n",
    "    ytr,yvl = Y_train[train_index],Y_train[test_index]      \n",
    "    \n",
    "    model = XGBClassifier(n_estimators=50, max_depth=4,weights = weight,scale_pos_weight=scale_pos_weight)     \n",
    "    model.fit(xtr, ytr)     \n",
    "    pred_test = model.predict(xvl)     \n",
    "    score = accuracy_score(yvl,pred_test)     \n",
    "    print('accuracy_score',score)     \n",
    "    i+=1 \n",
    "pred_test = model.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_11th_April_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['session_id', 'startTime', 'endTime', 'ProductList', 'gender',\n",
       "        'NumProduct', 'FirstA', 'FirstB', 'FirstC', 'FirstD', 'UniqueA',\n",
       "        'UniqueB', 'UniqueC', 'UniqueD', 'MostA', 'duration', 'weekday',\n",
       "        'hour_24h'],\n",
       "       dtype='object'),\n",
       " Index(['NumProduct', 'UniqueA', 'UniqueB', 'UniqueC', 'UniqueD', 'duration',\n",
       "        'weekday', 'hour_24h', 'FirstA_A00001', 'FirstA_A00002',\n",
       "        ...\n",
       "        'MostA_A00002', 'MostA_A00003', 'MostA_A00004', 'MostA_A00005',\n",
       "        'MostA_A00006', 'MostA_A00007', 'MostA_A00008', 'MostA_A00009',\n",
       "        'MostA_A00010', 'MostA_A00011'],\n",
       "       dtype='object', length=11548))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,X_train.columns\n",
    "#train['MostA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lst = ['day', 'weekend','FirstAmeantarget', 'FirstBmeantarget','FirstCmeantarget', 'FirstDmeantarget', 'MostAmeantarget']\n",
    "\n",
    "X_train = data.loc[data.gender.isnull() == False].drop(drop_lst,axis =1 )\n",
    "Y_train = train['gender']\n",
    "X_train = X_train.drop('gender',axis = 1)\n",
    "\n",
    "X_test =  data.loc[data.gender.isnull()] .drop(drop_lst,axis =1 )\n",
    "X_test = X_test.drop('gender',axis = 1)\n",
    "X_train= X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'learning_rate': 0.001,\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'accuracy',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's auc: 0.898724\tvalid_1's auc: 0.841062\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's auc: 0.92218\tvalid_1's auc: 0.825683\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's auc: 0.899568\tvalid_1's auc: 0.843894\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's auc: 0.920521\tvalid_1's auc: 0.821462\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.871038\tvalid_1's auc: 0.850384\n",
      "accuracy_score 0.8434285714285714\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,Y_train)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=Y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], label=Y_train.iloc[val_idx])\n",
    "   \n",
    "    num_round = 10000\n",
    "    #clf = lgb.LGBMClassifier(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 100)\n",
    "    clf = lgb.train(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X_train.columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "#np.sqrt(mean_squared_error(oof, target))\n",
    "oof = np.where(oof > 0.5, 1, 0)\n",
    "score = accuracy_score(oof,Y_train)     \n",
    "print('accuracy_score',score)  \n",
    "pred_test = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.21980952380952382\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(oof,Y_train)     \n",
    "print('accuracy_score',score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_12th_April_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's auc: 0.916157\tvalid_1's auc: 0.829801\n",
      "fold 1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's auc: 0.907295\tvalid_1's auc: 0.838157\n",
      "fold 2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's auc: 0.917967\tvalid_1's auc: 0.847921\n",
      "fold 3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's auc: 0.897484\tvalid_1's auc: 0.848312\n",
      "fold 4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's auc: 0.931808\tvalid_1's auc: 0.825548\n",
      "fold 5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's auc: 0.888622\tvalid_1's auc: 0.844801\n",
      "fold 6\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's auc: 0.941095\tvalid_1's auc: 0.801864\n",
      "fold 7\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's auc: 0.907733\tvalid_1's auc: 0.853031\n",
      "fold 8\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's auc: 0.936696\tvalid_1's auc: 0.833479\n",
      "fold 9\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[470]\ttraining's auc: 0.930244\tvalid_1's auc: 0.846881\n",
      "fold 10\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's auc: 0.899493\tvalid_1's auc: 0.840116\n",
      "fold 11\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's auc: 0.907231\tvalid_1's auc: 0.843372\n",
      "fold 12\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's auc: 0.90965\tvalid_1's auc: 0.835451\n",
      "fold 13\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's auc: 0.92822\tvalid_1's auc: 0.835361\n",
      "fold 14\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's auc: 0.899594\tvalid_1's auc: 0.832211\n",
      "fold 15\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's auc: 0.898602\tvalid_1's auc: 0.849818\n",
      "fold 16\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's auc: 0.918801\tvalid_1's auc: 0.836464\n",
      "fold 17\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's auc: 0.888921\tvalid_1's auc: 0.854383\n",
      "fold 18\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's auc: 0.917762\tvalid_1's auc: 0.821853\n",
      "fold 19\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[367]\ttraining's auc: 0.927689\tvalid_1's auc: 0.836498\n",
      "accuracy_score 0.21980952380952382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=4, random_state=4520)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "#start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,Y_train)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=Y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], label=Y_train.iloc[val_idx])\n",
    "   \n",
    "    num_round = 10000\n",
    "    clf = lgb.LGBMClassifier(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 500)\n",
    "    clf = lgb.train(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 500)\n",
    "    oof[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X_train.columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / (5 * 4)\n",
    "\n",
    "oof = np.where(oof > 0.5, 1, 0)\n",
    "score = accuracy_score(oof,Y_train)     \n",
    "print('accuracy_score',score)  \n",
    "pred_test = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_12th_April_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['gender'] = 1\n",
    "X_train['gender'] = Y_train\n",
    "\n",
    "X_train_1 = X_train.loc[X_train.gender == 1]\n",
    "X_train_0 = X_train.loc[X_train.gender == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8192, 11549), (2308, 11549))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape,X_train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100000\n",
       "0    100000\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Down Sample\n",
    "from sklearn.utils import resample\n",
    "n_samples = 100000\n",
    "X_train_0 = resample(X_train_0,\n",
    "                                replace = True, \n",
    "                                n_samples = n_samples,\n",
    "                                random_state = 27)\n",
    "\n",
    "X_train_1 = resample(X_train_1,\n",
    "                                replace = True,\n",
    "                                n_samples = n_samples,\n",
    "                                random_state = 27)\n",
    "\n",
    "downsampled = pd.concat([X_train_0, X_train_1])\n",
    "downsampled['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 11549)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.shape\n",
    "downsampled_Y = downsampled.gender\n",
    "downsampled.drop(['gender'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4719]\ttraining's auc: 0.999964\tvalid_1's auc: 0.999933\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5634]\ttraining's auc: 0.999987\tvalid_1's auc: 0.99998\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6320]\ttraining's auc: 0.999987\tvalid_1's auc: 0.999981\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5339]\ttraining's auc: 0.999981\tvalid_1's auc: 0.999975\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3578]\ttraining's auc: 0.999726\tvalid_1's auc: 0.999552\n",
      "accuracy_score 0.995505\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof = np.zeros(len(downsampled_Y))\n",
    "predictions = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(downsampled,downsampled_Y)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(downsampled.iloc[trn_idx], label=downsampled_Y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(downsampled.iloc[val_idx], label=downsampled_Y.iloc[val_idx])\n",
    "   \n",
    "    num_round = 10000\n",
    "    #clf = lgb.LGBMClassifier(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 100)\n",
    "    clf = lgb.train(parameters, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(downsampled.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    #fold_importance_df = pd.DataFrame()\n",
    "    #fold_importance_df[\"Feature\"] = X_train.columns\n",
    "    #fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    #fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "#np.sqrt(mean_squared_error(oof, target))\n",
    "oof = np.where(oof > 0.5, 1, 0)\n",
    "score = accuracy_score(oof,downsampled_Y)     \n",
    "print('accuracy_score',score)  \n",
    "pred_test = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_test, columns=[\"gender\"])\n",
    "results['gender'] = results['gender'].map({1:'female',0:'male'})\n",
    "sample_sub['gender'] = results['gender']\n",
    "sample_sub.to_csv('sample_submission_12th_April_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finished"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
