{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.16.2\n",
      "pandas 0.23.4\n",
      "scipy 1.1.0\n",
      "sklearn 0.19.2\n",
      "lightgbm 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "from catboost import Pool\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import catboost\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.time()\n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lightgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):   \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('input/sales_train_v2.csv')\n",
    "shops = pd.read_csv('input/shops.csv')\n",
    "items = pd.read_csv('input/items.csv')\n",
    "item_cats = pd.read_csv('input/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales = sales[sales['shop_id'].isin([26, 27, 28])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('input/test.csv', dtype={'ID': 'int32', 'shop_id': 'int32','item_id': 'int32'})\n",
    "test['date_block_num'] = 34\n",
    "test.drop(['ID'], axis=1, inplace=True)\n",
    "#test =  test.merge(item_categories[['item_cat_id_fix', 'item_category_id']], on = ['item_category_id'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "\n",
    "# Fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "\n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnielG\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([all_data, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1045fe333184f77aae3874a092619c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "\n",
    "del train_shift\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mean Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 34\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates_train = dates[dates <  last_block]\n",
    "#dates_val = dates[dates ==  last_block - 1]\n",
    "dates_test  = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block].drop(to_drop_cols, axis=1)\n",
    "#X_val = all_data.loc[dates ==  last_block - 1].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "#y_val = all_data.loc[dates ==  last_block - 1, 'target'].values\n",
    "y_test =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for linreg is 0.255000\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train.values, y_train)\n",
    "#pred_val_lr = lr.predict(X_val.values)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "\n",
    "#print('Test R-squared for linreg is %f' % r2_score(y_val, pred_val_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "#pred_val_lgb = model.predict(X_val)\n",
    "pred_lgb = model.predict(X_test)\n",
    "print(y_test.shape)\n",
    "\n",
    "#print('Test R-squared for LightGBM is %f' % r2_score(y_val, pred_val_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB - , (validation, Y_validation)\n",
    "xgb_model = XGBRegressor(max_depth=8, \n",
    "                         n_estimators=500, \n",
    "                         min_child_weight=1000,  \n",
    "                         colsample_bytree=0.7, \n",
    "                         subsample=0.7, \n",
    "                         eta=0.3, \n",
    "                         seed=0)\n",
    "xgb_model.fit(train, \n",
    "              Y_train, \n",
    "              eval_metric=\"rmse\", \n",
    "              eval_set=[(X_train, y_train)], \n",
    "              verbose=20,\n",
    "              early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 214200)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_lr),len(pred_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200, 2)\n"
     ]
    }
   ],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb]\n",
    "print(X_test_level2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32,33])]\n",
    "\n",
    "# That is how we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32, 33])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "slice_start = 0\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32, 33]:\n",
    "    preds = []        \n",
    "\n",
    "    print(cur_block_num)\n",
    "    \n",
    "    X_train = all_data.loc[dates <  cur_block_num].drop(to_drop_cols, axis=1)\n",
    "    X_test =  all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis=1)\n",
    "    \n",
    "    y_train = all_data.loc[dates <  cur_block_num, 'target'].values\n",
    "    \n",
    "    # Fit LinearRegression\n",
    "    lr.fit(X_train.values, y_train)\n",
    "    pred_lr = lr.predict(X_test.values)\n",
    "    \n",
    "    # Fit LGB\n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "    pred_lgb = model.predict(X_test)\n",
    "    \n",
    "    # Fit KNN Model\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=9, leaf_size=13, n_jobs=-1)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_pred = knn_model.predict(X_test)\n",
    "    \n",
    "    # Fit Random Forest    \n",
    "    rf_model = RandomForestRegressor(n_estimators=50, max_depth=7, random_state=0, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Fit XGB\n",
    "    xgb_model.fit(X_train, \n",
    "              y_train, \n",
    "              #eval_metric=\"rmse\", \n",
    "              #eval_set=[(X_train, y_train)], \n",
    "              verbose=20,\n",
    "              early_stopping_rounds=20)\n",
    "    xgb_pred = xgb_model.predict(test)\n",
    "    \n",
    "    preds.append(pred_lr)\n",
    "    preds.append(pred_lgb)\n",
    "    preds.append(xgb_pred)\n",
    "    preds.append(knn_pred)    \n",
    "    preds.append(rf_pred)\n",
    "        \n",
    "    indexes = dates_train_level2.index[dates_train_level2 == cur_block_num]\n",
    "    \n",
    "    #for i in range(pred_lgb.shape[0]):\n",
    "    #    X_train_level2[indexes[i] - 120192 ] = [pred_lr[i], pred_lgb[i]] \n",
    "        \n",
    "    slice_end = slice_start + X_test.shape[0]\n",
    "    X_train_level2[slice_start : slice_end , :] = np.c_[preds].transpose()\n",
    "    slice_start = slice_end\n",
    "    \n",
    "    \n",
    "# Sanity check\n",
    "#assert np.all(np.isclose(X_train_level2.mean(axis=0), [ 1.50148988,  1.38811989]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614364, 1376192)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1614364,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1614364,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_end,slice_start\n",
    "#len(np.c_[preds].transpose())\n",
    "#X_train_level2[slice_start : slice_end , :] = np.c_[preds].transpose()\n",
    "#X_train_level2[slice_start : slice_end].shape\n",
    "#y_train_level2.shape[0]\n",
    "\n",
    "y_train[dates_train.isin([27, 28, 29, 30, 31, 32, 33])].shape\n",
    "dates_train[dates_train.isin([27, 28, 29, 30, 31, 32,33])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.298000; Corresponding r2 score on train: 0.266232\n"
     ]
    }
   ],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "\n",
    "best_alpha = -1\n",
    "r2_train_simple_mix = -1\n",
    "\n",
    "for current_alpha in alphas_to_try:\n",
    "    mix = current_alpha * X_train_level2[:,0] + (1 - current_alpha) * X_train_level2[:,1]\n",
    "    current_r2 = r2_score(y_train_level2, mix)\n",
    "    if(current_r2 > r2_train_simple_mix):\n",
    "        r2_train_simple_mix = current_r2\n",
    "        best_alpha = current_alpha\n",
    "\n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for simple mix is 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_preds = best_alpha * X_test_level2[:,0] + (1 - best_alpha) * X_test_level2[:,1]\n",
    "\n",
    "#r2_test_simple_mix = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Test R-squared for simple mix is %f' % r2_test_simple_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for stacking is 0.269972\n",
      "Test  R-squared for stacking is 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train_level2)\n",
    "r2_train_stacking = r2_score(y_train_level2, train_preds)\n",
    "\n",
    "test_preds = lr.predict(X_test_level2)\n",
    "#r2_test_stacking = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
    "#print('Test  R-squared for stacking is %f' % r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.514411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.294990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.446523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.469430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.067788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.191685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.327031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.320749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        0.514411\n",
       "1   1        0.143912\n",
       "2   2        0.945865\n",
       "3   3        0.294990\n",
       "4   4        1.446523\n",
       "5   5        0.469430\n",
       "6   6        1.067788\n",
       "7   7        0.191685\n",
       "8   8        1.327031\n",
       "9   9        0.320749"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write to file to Submit\n",
    "test = pd.read_csv('input/test.csv', dtype={'ID': 'int32', 'shop_id': 'int32','item_id': 'int32'})\n",
    "prediction_df = pd.DataFrame(test['ID'], columns=['ID'])\n",
    "prediction_df['item_cnt_month'] = test_preds.clip(0., 20.)\n",
    "prediction_df.to_csv('submission_final.csv', index=False)\n",
    "prediction_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
