{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oniel Gracious - Competition 3 - Santander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.patches as patch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import NuSVR\n",
    "from scipy.stats import norm\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import time\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 201))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify real ids and fake ID's from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:06<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Brilliant discovery for this competition, this was the secret to the magic variable. I didnt find it.\n",
    "df_test = test[features]\n",
    "#df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] = 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 200))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake_ids = list(synthetic_samples_indexes) #np.load('input/synthetic_samples_indexes.npy')\n",
    "\n",
    "ids = np.arange(test.shape[0])\n",
    "\n",
    "real_ids = list(set(ids) - set(fake_ids)) # NICE\n",
    "\n",
    "real_test = test.iloc[real_ids]\n",
    "fake_test = test.iloc[fake_ids]\n",
    "real_test_id = real_test.ID_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['target', 'ID_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the difference between Var and the Feature...now we have 400 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebc933b218449bcaae31c754bf80aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79f31aa93df49ba9e9d866eabda888a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train,real_test], axis = 0)\n",
    "\n",
    "for feat in tqdm_notebook(features):\n",
    "    df[feat+'_var'] = df.groupby([feat])[feat].transform('var')\n",
    "    \n",
    "for feat in tqdm_notebook(features):\n",
    "    df[feat+'plus_'] = df[feat] + df[feat+'_var']\n",
    "    # df[feat+'minus_'] = df[feat] - df[feat+'_var'] this is not necessary\n",
    "\n",
    "drop_features = [c for c in df.columns if '_var' in c]\n",
    "df.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:train.shape[0]]\n",
    "real_test = df.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "# Add Row Level Features\n",
    "%%time\n",
    "idx = features = train_df.columns.values[2:202]\n",
    "\n",
    "#for df in [train, real_test]:\n",
    "train['sum'] = train[idx].sum(axis=1)  \n",
    "train['min'] = train[idx].min(axis=1)\n",
    "train['max'] = train[idx].max(axis=1)\n",
    "train['mean'] = train[idx].mean(axis=1)\n",
    "train['std'] = train[idx].std(axis=1)\n",
    "train['skew'] = train[idx].skew(axis=1)\n",
    "train['kurt'] = train[idx].kurtosis(axis=1)\n",
    "train['med'] = train[idx].median(axis=1)\n",
    "    \n",
    "#for df in [train, real_test]:\n",
    "real_test['sum'] = real_test[idx].sum(axis=1)  \n",
    "real_test['min'] = real_test[idx].min(axis=1)\n",
    "real_test['max'] = real_test[idx].max(axis=1)\n",
    "real_test['mean'] = real_test[idx].mean(axis=1)\n",
    "real_test['std'] = real_test[idx].std(axis=1)\n",
    "real_test['skew'] = real_test[idx].skew(axis=1)\n",
    "real_test['kurt'] = real_test[idx].kurtosis(axis=1)\n",
    "real_test['med'] = real_test[idx].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encode\n",
    "def frequency_encoding(variable):\n",
    "    t = pd.concat([train[variable], real_test[variable]]).value_counts().reset_index()\n",
    "    t = t.reset_index()\n",
    "    t.loc[t[variable] == 1, 'level_0'] = np.nan\n",
    "    t.set_index('index', inplace=True)\n",
    "    max_label = t['level_0'].max() + 1\n",
    "    t.fillna(max_label, inplace=True)\n",
    "    return t.to_dict()['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5242c8a4144a3598884958f8377360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Frequency Encoding - Didnt Work\n",
    "#from tqdm import tqdm_notebook\n",
    "#cols = []\n",
    "#cols = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "\n",
    "##for df in [train, real_test]:\n",
    "#for col in tqdm_notebook(cols):\n",
    "#    freq_enc_dict = frequency_encoding(col)\n",
    "#    train['encode_FE' + col] = train[col].map(lambda x: freq_enc_dict.get(x, np.nan))\n",
    "#    real_test['encode_FE' + col] = real_test[col].map(lambda x: freq_enc_dict.get(x, np.nan))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "target = train['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 802)\n",
      "(100000, 802)\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(real_test.shape)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,  'bagging_fraction': 0.4,  'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',    'feature_fraction': 0.04, 'learning_rate': 0.01,\n",
    "    'max_depth': -1,    'metric':'auc',             'min_data_in_leaf': 80,\n",
    "    'num_leaves': 13,  'num_threads': 8,            \n",
    "    'tree_learner': 'serial',   'objective': 'binary',       'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4242)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(real_test))\n",
    "val_aucs = []\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[5000]\ttraining's auc: 0.95253\tvalid_1's auc: 0.92293\n",
      "[10000]\ttraining's auc: 0.974282\tvalid_1's auc: 0.924532\n",
      "Early stopping, best iteration is:\n",
      "[10817]\ttraining's auc: 0.976889\tvalid_1's auc: 0.92458\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[5000]\ttraining's auc: 0.952809\tvalid_1's auc: 0.921332\n",
      "[10000]\ttraining's auc: 0.974394\tvalid_1's auc: 0.92303\n",
      "Early stopping, best iteration is:\n",
      "[10021]\ttraining's auc: 0.974462\tvalid_1's auc: 0.923043\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[5000]\ttraining's auc: 0.953069\tvalid_1's auc: 0.917857\n",
      "[10000]\ttraining's auc: 0.974759\tvalid_1's auc: 0.919899\n",
      "Early stopping, best iteration is:\n",
      "[9782]\ttraining's auc: 0.974009\tvalid_1's auc: 0.919972\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[5000]\ttraining's auc: 0.953068\tvalid_1's auc: 0.920307\n",
      "[10000]\ttraining's auc: 0.974559\tvalid_1's auc: 0.922445\n",
      "[15000]\ttraining's auc: 0.987757\tvalid_1's auc: 0.922276\n",
      "Early stopping, best iteration is:\n",
      "[12759]\ttraining's auc: 0.982701\tvalid_1's auc: 0.922545\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[5000]\ttraining's auc: 0.953456\tvalid_1's auc: 0.916868\n",
      "[10000]\ttraining's auc: 0.975036\tvalid_1's auc: 0.919149\n",
      "[15000]\ttraining's auc: 0.988105\tvalid_1's auc: 0.919298\n",
      "Early stopping, best iteration is:\n",
      "[13434]\ttraining's auc: 0.984766\tvalid_1's auc: 0.919428\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 3000)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    val_aucs.append(roc_auc_score(target[val_idx] , oof[val_idx] ))\n",
    "    \n",
    "    predictions += clf.predict(real_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean auc: 0.921913832, std: 0.001935783. All auc: 0.921809452.\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.mean(val_aucs)\n",
    "std_auc = np.std(val_aucs)\n",
    "all_auc = roc_auc_score(target, oof)\n",
    "print(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreal = pd.DataFrame({\"ID_code\": real_test_id.values})\n",
    "subreal['target']=predictions\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsub = sub.set_index('ID_code').join(subreal.set_index('ID_code')).reset_index()\n",
    "finalsub.fillna(0,inplace=True)\n",
    "finalsub.to_csv(\"submission-Late1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(train, target, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>...</th>\n",
       "      <th>encode_FEvar_190plus_</th>\n",
       "      <th>encode_FEvar_191plus_</th>\n",
       "      <th>encode_FEvar_192plus_</th>\n",
       "      <th>encode_FEvar_193plus_</th>\n",
       "      <th>encode_FEvar_194plus_</th>\n",
       "      <th>encode_FEvar_195plus_</th>\n",
       "      <th>encode_FEvar_196plus_</th>\n",
       "      <th>encode_FEvar_197plus_</th>\n",
       "      <th>encode_FEvar_198plus_</th>\n",
       "      <th>encode_FEvar_199plus_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76034</th>\n",
       "      <td>train_76034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3756</td>\n",
       "      <td>-1.3213</td>\n",
       "      <td>0.5893</td>\n",
       "      <td>-15.4467</td>\n",
       "      <td>5.4248</td>\n",
       "      <td>21.2245</td>\n",
       "      <td>1.6883</td>\n",
       "      <td>9.7037</td>\n",
       "      <td>...</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>13266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25496.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16348.0</td>\n",
       "      <td>30478.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51652</th>\n",
       "      <td>train_51652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3689</td>\n",
       "      <td>-3.9301</td>\n",
       "      <td>-4.7831</td>\n",
       "      <td>19.5275</td>\n",
       "      <td>20.0585</td>\n",
       "      <td>21.5887</td>\n",
       "      <td>1.8115</td>\n",
       "      <td>11.1366</td>\n",
       "      <td>...</td>\n",
       "      <td>17712.0</td>\n",
       "      <td>57889.0</td>\n",
       "      <td>15427.0</td>\n",
       "      <td>5559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6549.0</td>\n",
       "      <td>30353.0</td>\n",
       "      <td>24905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138222</th>\n",
       "      <td>train_138222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0033</td>\n",
       "      <td>-8.8002</td>\n",
       "      <td>7.3013</td>\n",
       "      <td>-8.1361</td>\n",
       "      <td>24.3871</td>\n",
       "      <td>31.1576</td>\n",
       "      <td>1.4519</td>\n",
       "      <td>9.1671</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15330.0</td>\n",
       "      <td>27878.0</td>\n",
       "      <td>61579.0</td>\n",
       "      <td>69644.0</td>\n",
       "      <td>10058.0</td>\n",
       "      <td>12363.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115575</th>\n",
       "      <td>train_115575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3624</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>-6.2352</td>\n",
       "      <td>-13.2246</td>\n",
       "      <td>11.4086</td>\n",
       "      <td>12.5656</td>\n",
       "      <td>1.5613</td>\n",
       "      <td>12.4782</td>\n",
       "      <td>...</td>\n",
       "      <td>65519.0</td>\n",
       "      <td>5683.0</td>\n",
       "      <td>51088.0</td>\n",
       "      <td>40269.0</td>\n",
       "      <td>11829.0</td>\n",
       "      <td>9252.0</td>\n",
       "      <td>43372.0</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45249</th>\n",
       "      <td>train_45249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3283</td>\n",
       "      <td>-7.8924</td>\n",
       "      <td>12.3823</td>\n",
       "      <td>0.4774</td>\n",
       "      <td>10.3129</td>\n",
       "      <td>36.7297</td>\n",
       "      <td>1.6154</td>\n",
       "      <td>6.9304</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9276.0</td>\n",
       "      <td>4328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>841.0</td>\n",
       "      <td>46093.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>39104.0</td>\n",
       "      <td>37229.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1   var_10  var_100  var_101  \\\n",
       "76034    train_76034     0.0  10.3756 -1.3213   0.5893 -15.4467   5.4248   \n",
       "51652    train_51652     0.0   7.3689 -3.9301  -4.7831  19.5275  20.0585   \n",
       "138222  train_138222     1.0   8.0033 -8.8002   7.3013  -8.1361  24.3871   \n",
       "115575  train_115575     0.0  13.3624  0.8846  -6.2352 -13.2246  11.4086   \n",
       "45249    train_45249     0.0   9.3283 -7.8924  12.3823   0.4774  10.3129   \n",
       "\n",
       "        var_102  var_103  var_104          ...            \\\n",
       "76034   21.2245   1.6883   9.7037          ...             \n",
       "51652   21.5887   1.8115  11.1366          ...             \n",
       "138222  31.1576   1.4519   9.1671          ...             \n",
       "115575  12.5656   1.5613  12.4782          ...             \n",
       "45249   36.7297   1.6154   6.9304          ...             \n",
       "\n",
       "        encode_FEvar_190plus_  encode_FEvar_191plus_  encode_FEvar_192plus_  \\\n",
       "76034                  2197.0                13266.0                    NaN   \n",
       "51652                 17712.0                57889.0                15427.0   \n",
       "138222                    NaN                15330.0                27878.0   \n",
       "115575                65519.0                 5683.0                51088.0   \n",
       "45249                     NaN                 9276.0                 4328.0   \n",
       "\n",
       "        encode_FEvar_193plus_  encode_FEvar_194plus_  encode_FEvar_195plus_  \\\n",
       "76034                 25496.0                    NaN                 2021.0   \n",
       "51652                  5559.0                    NaN                15810.0   \n",
       "138222                61579.0                69644.0                10058.0   \n",
       "115575                40269.0                11829.0                 9252.0   \n",
       "45249                     NaN                    NaN                  841.0   \n",
       "\n",
       "        encode_FEvar_196plus_  encode_FEvar_197plus_  encode_FEvar_198plus_  \\\n",
       "76034                     NaN                16348.0                30478.0   \n",
       "51652                     NaN                 6549.0                30353.0   \n",
       "138222                12363.0                 1133.0                    NaN   \n",
       "115575                43372.0                11306.0                    NaN   \n",
       "45249                 46093.0                  204.0                39104.0   \n",
       "\n",
       "        encode_FEvar_199plus_  \n",
       "76034                     NaN  \n",
       "51652                 24905.0  \n",
       "138222                40181.0  \n",
       "115575                    NaN  \n",
       "45249                 37229.0  \n",
       "\n",
       "[5 rows x 802 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1eaa8a45f28>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cat\n",
    "train_pool = Pool(train_X[features],train_y)\n",
    "cat_model = CatBoostClassifier(\n",
    "                               iterations=3000,# change 25 to 3000 to get best performance \n",
    "                               learning_rate=0.03,\n",
    "                               objective=\"Logloss\",\n",
    "                               eval_metric='AUC',\n",
    "                              )\n",
    "cat_model.fit(train_X[features],train_y,silent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 800), 0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X.replace(np.nan, 0)\n",
    "val_X = val_X.replace(np.nan, 0)\n",
    "\n",
    "train = train.replace(np.nan, 0)\n",
    "real_test = real_test.replace(np.nan, 0)\n",
    "\n",
    "train_X[features].shape,train_X[features].isnull().sum().sum()\n",
    "#,train_X[features].isnan().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_0                    0\n",
       "var_1                    0\n",
       "var_10                   0\n",
       "var_100                  0\n",
       "var_101                  0\n",
       "var_102                  0\n",
       "var_103                  0\n",
       "var_104                  0\n",
       "var_105                  0\n",
       "var_106                  0\n",
       "var_107                  0\n",
       "var_108                  0\n",
       "var_109                  0\n",
       "var_11                   0\n",
       "var_110                  0\n",
       "var_111                  0\n",
       "var_112                  0\n",
       "var_113                  0\n",
       "var_114                  0\n",
       "var_115                  0\n",
       "var_116                  0\n",
       "var_117                  0\n",
       "var_118                  0\n",
       "var_119                  0\n",
       "var_12                   0\n",
       "var_120                  0\n",
       "var_121                  0\n",
       "var_122                  0\n",
       "var_123                  0\n",
       "var_124                  0\n",
       "                        ..\n",
       "encode_FEvar_170plus_    0\n",
       "encode_FEvar_171plus_    0\n",
       "encode_FEvar_172plus_    0\n",
       "encode_FEvar_173plus_    0\n",
       "encode_FEvar_174plus_    0\n",
       "encode_FEvar_175plus_    0\n",
       "encode_FEvar_176plus_    0\n",
       "encode_FEvar_177plus_    0\n",
       "encode_FEvar_178plus_    0\n",
       "encode_FEvar_179plus_    0\n",
       "encode_FEvar_180plus_    0\n",
       "encode_FEvar_181plus_    0\n",
       "encode_FEvar_182plus_    0\n",
       "encode_FEvar_183plus_    0\n",
       "encode_FEvar_184plus_    0\n",
       "encode_FEvar_185plus_    0\n",
       "encode_FEvar_186plus_    0\n",
       "encode_FEvar_187plus_    0\n",
       "encode_FEvar_188plus_    0\n",
       "encode_FEvar_189plus_    0\n",
       "encode_FEvar_190plus_    0\n",
       "encode_FEvar_191plus_    0\n",
       "encode_FEvar_192plus_    0\n",
       "encode_FEvar_193plus_    0\n",
       "encode_FEvar_194plus_    0\n",
       "encode_FEvar_195plus_    0\n",
       "encode_FEvar_196plus_    0\n",
       "encode_FEvar_197plus_    0\n",
       "encode_FEvar_198plus_    0\n",
       "encode_FEvar_199plus_    0\n",
       "Length: 800, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rfc_model = RandomForestClassifier(random_state=0).fit(train_X[features], train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X[features], train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Models\n",
    "#y_pred_lgb_train = lgb.predict(train[features])\n",
    "y_pred_cat_train = cat_model.predict(train[features])\n",
    "y_pred_rfc_train = rfc_model.predict(train[features])\n",
    "y_pred_tree_train = tree_model.predict(train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost Mean auc: 0.053460000, std: 0.224948946. All auc: 0.734882055.\n",
      "Random Forest Mean auc: 0.065680000, std: 0.247721896. All auc: 0.825249873.\n",
      "Decison Tree Mean auc: 0.003675000, std: 0.060510283. All auc: 0.511177453.\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "# Cat Boost\n",
    "mean_auc = np.mean(y_pred_cat_train)\n",
    "std_auc = np.std(y_pred_cat_train)\n",
    "all_auc = roc_auc_score(target, y_pred_cat_train)\n",
    "print(\"Cat Boost Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))\n",
    "\n",
    "# Random Forest\n",
    "mean_auc = np.mean(y_pred_rfc_train)\n",
    "std_auc = np.std(y_pred_rfc_train)\n",
    "all_auc = roc_auc_score(target, y_pred_rfc_train)\n",
    "print(\"Random Forest Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))\n",
    "\n",
    "# Decision Tree\n",
    "mean_auc = np.mean(y_pred_tree_train)\n",
    "std_auc = np.std(y_pred_tree_train)\n",
    "all_auc = roc_auc_score(target, y_pred_tree_train)\n",
    "print(\"Decison Tree Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on Test\n",
    "#y_pred_lgb_train = lgb.predict(X)\n",
    "y_pred_cat = cat_model.predict(real_test[features])\n",
    "y_pred_rfc = rfc_model.predict(real_test[features])\n",
    "y_pred_tree = tree_model.predict(real_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble and Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_boost</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.729258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_boost  random_forest  decision_tree       lgb\n",
       "0         0.0            0.0            0.0  0.001657\n",
       "1         0.0            0.0            0.0  0.548527\n",
       "2         0.0            0.0            0.0  0.005902\n",
       "3         0.0            0.0            0.0  0.044770\n",
       "4         0.0            0.0            0.0  0.040842\n",
       "5         0.0            0.0            0.0  0.015414\n",
       "6         0.0            0.0            0.0  0.161597\n",
       "7         0.0            0.0            0.0  0.018159\n",
       "8         0.0            0.0            0.0  0.093118\n",
       "9         0.0            0.0            0.0  0.017863\n",
       "10        0.0            0.0            0.0  0.011672\n",
       "11        0.0            0.0            0.0  0.033821\n",
       "12        0.0            0.0            0.0  0.012490\n",
       "13        1.0            0.0            0.0  0.729258\n",
       "14        0.0            0.0            0.0  0.047785\n",
       "15        0.0            0.0            0.0  0.158229\n",
       "16        0.0            0.0            0.0  0.002480\n",
       "17        0.0            0.0            0.0  0.016599\n",
       "18        0.0            0.0            0.0  0.054988\n",
       "19        0.0            0.0            0.0  0.006578"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset that will be the train set of the ensemble model.\n",
    "first_level = pd.DataFrame()\n",
    "first_level['cat_boost'] = y_pred_cat_train\n",
    "first_level['random_forest'] = y_pred_rfc_train\n",
    "first_level['decision_tree'] = y_pred_tree_train\n",
    "first_level['lgb'] = oof\n",
    "#first_level['target'] = target.values\n",
    "first_level.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_boost</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_boost  random_forest  decision_tree       lgb\n",
       "0         0.0            0.0            0.0  0.140687\n",
       "1         0.0            0.0            0.0  0.067085\n",
       "2         0.0            0.0            0.0  0.023961\n",
       "3         0.0            0.0            0.0  0.025297\n",
       "4         0.0            0.0            0.0  0.448054\n",
       "5         0.0            0.0            0.0  0.020525\n",
       "6         0.0            0.0            0.0  0.074498\n",
       "7         1.0            1.0            0.0  0.559852\n",
       "8         0.0            0.0            0.0  0.044138\n",
       "9         0.0            0.0            0.0  0.009910\n",
       "10        0.0            0.0            0.0  0.006522\n",
       "11        0.0            0.0            0.0  0.015275\n",
       "12        0.0            0.0            0.0  0.013446\n",
       "13        0.0            0.0            0.0  0.006783\n",
       "14        0.0            0.0            0.0  0.119930\n",
       "15        0.0            0.0            0.0  0.012085\n",
       "16        0.0            0.0            0.0  0.003579\n",
       "17        0.0            0.0            0.0  0.021292\n",
       "18        0.0            0.0            0.0  0.010875\n",
       "19        0.0            0.0            0.0  0.007621"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset that will be the test set of the ensemble model.\n",
    "first_level_test = pd.DataFrame()\n",
    "first_level_test['cat_boost'] = y_pred_cat\n",
    "first_level_test['random_forest'] = y_pred_rfc\n",
    "first_level_test['decision_tree'] = y_pred_tree\n",
    "first_level_test['lgb'] = predictions\n",
    "first_level_test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble architecture:\n",
    "\n",
    "1st level:\n",
    "Catboost\n",
    "XGBM\n",
    "Random forest\n",
    "Linear Regression\n",
    "KNN\n",
    "\n",
    "2nd level;\n",
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model.fit(first_level, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = meta_model.predict(first_level)\n",
    "final_predictions = meta_model.predict(first_level_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost Mean auc: 0.100490000, std: 0.251728893. All auc: 0.969339222.\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.mean(ensemble_pred)\n",
    "std_auc = np.std(ensemble_pred)\n",
    "all_auc = roc_auc_score(target, ensemble_pred)\n",
    "print(\"Cat Boost Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreal = pd.DataFrame({\"ID_code\": real_test_id.values})\n",
    "subreal['target']=final_predictions\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsub = sub.set_index('ID_code').join(subreal.set_index('ID_code')).reset_index()\n",
    "finalsub.fillna(0,inplace=True)\n",
    "finalsub.to_csv(\"submission-Late2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=submission-Late2.csv>Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NICE\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='submission-Late2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
